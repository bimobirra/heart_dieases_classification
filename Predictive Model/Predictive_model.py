# -*- coding: utf-8 -*-
"""Predictive Analytics Bimo Birra.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-SwPFWB-sBv724C4O_WqZqF8hkpJCNRT

# Business Understanding

Penyakit jantung atau yang dikenal dengan penyakit kardiovaskular adalah salah satu penyakit yang menyebabkan kematian secara global, diperkirakan kematian dari penyakit ini mencapai 17,9 juta dalam tahun 2019. Sangat penting untuk mendeteksi penyakit seawal mungkin agar bisa dicegah seperti konseling beserta pemberian obat-obat bisa dimulai

# Import Library
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score

"""#Data Understanding

Data yang digunakan Heart Disease Classification Dataset

link : https://www.kaggle.com/datasets/bharath011/heart-disease-classification-dataset

Dataset ini memiliki 1319 baris data dengan 9 kolom

Fitur-fitur yang terdapat dalam dataset:
1. age : Umur dari pasien
2. gender : Jenis kelamin dari pasien
3. impulse : Sinyal listrik yang dihasilkan oleh jantung
4. preassurehigh : Tekanan maksimum saat jantung berkontraksi
5. preassurelow : Tekanan minimum saat jantung berkontraksi
6. glucose : Kadar gula darah
7. kcm : Tiga mineral elektrolit yang sangat penting bagi fungsi jantung (Kalium(k), Kalsium(c), dan Magnesium(m))
8. troponin : Protein yang dilepaskan ke darah saat otot jantung rusak
9. class : Target dari model

## Data Loading
"""

# Menkonversi data .csv menjadi DataFrame Pandas
df = pd.read_csv('heart.csv')
df

# Mengubah nama kolom

df = df.rename(columns={'impluse': 'impulse', 'pressurehight':'preassurehigh', 'pressurelow': 'preassurelow'})

"""## Exploratory Data Analysis"""

# Mendapatkan kesimpulan dari DataFrame
df.info()

# Mendapatkan parameter statistik deskriptif dari DataFrame
df.describe()

# Memperiksa data yang hilang dari DataFrame
df.isnull().sum()

# Memperiksa data yang duplikat dari DataFrame
df.duplicated().sum()

# Memperiksa dimensi dari DataFrame
df.shape

# Memperiksa Outliers dengan boxplot
numeric_features = df.select_dtypes(include=['number']).columns

for column in numeric_features:
  plt.figure(figsize=(10, 6))
  sns.boxplot(x=df[column])
  plt.title(f'Boxplot dari kolom {column}')
  plt.show()

# Menghilangkan outliers
Q1 = df[numeric_features].quantile(0.25)
Q3 = df[numeric_features].quantile(0.75)
IQR = Q3 - Q1

upper = Q3 + 1.5 * IQR
lower = Q1 - 1.5 * IQR

filter_outliers = ~((df[numeric_features] < lower)| ( df[numeric_features] > upper)).any(axis=1)

clean_df = df[filter_outliers]

# Memperiksa dimensi DataFrame setelah dihilangkan outliers
clean_df.shape

"""### Univariate Analysis"""

target = clean_df['class']

# Menampilkan presentase setiap label
count = target.value_counts()
percentage = 100*target.value_counts(normalize=True)
target_df = pd.DataFrame({'jumlah_sampel': count, 'presentase': percentage.round(1)})
print(target_df)
print('\n')

# Visualisasi Bar Plot
count.plot(kind='bar', title='Jumlah Sample per label')
plt.show()

# Menampilkan histogram dari numerical features

clean_df.hist(bins=50, figsize=(20,15))
plt.show()

"""### Multivariate Analysis"""

# Mengencode target agar bisa dianalisis lebih lanjut

encoded_target = clean_df.copy()

encoder = LabelEncoder()
encoded_target['class'] = encoder.fit_transform(encoded_target['class'])

# Menampilkan pairplot dari Data Numerik
sns.pairplot(encoded_target, diag_kind='kde')
plt.show()

# Menampilkan heatmap

plt.figure(figsize=(10, 8))
correlation_matrix = encoded_target.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)
plt.show()

"""# Data Preparation"""

# Data Splitting

X = encoded_target.drop('class', axis=1)
y = encoded_target['class']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Data Scaling

scaler = StandardScaler()
X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])

X_train

# Jumlah sampel dari data latih dan data uji

n_training = len(X_train)
n_test = len(X_test)

print(f'Jumlah sampel data latih: {n_training}')
print(f'Jumlah sampel data uji: {n_test}')

"""# Modelling

## K-Nearest Neighbors
"""

# Inisialisasi Model KNN

knn = KNeighborsClassifier(n_neighbors=10)
knn.fit(X_train, y_train)

"""## Random Forest Classifer"""

# Inisialisasi Model RF

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)

"""# Evaluation"""

# Scaling pada data uji
X_test[numeric_features] = scaler.transform(X_test[numeric_features])

# Prediksi data uji
y_pred_knn = knn.predict(X_test)
y_pred_rf = rf.predict(X_test)

# Evaluasi dengan metriks

def evaluate(model: list, y_pred: list, name: list):
  """
  Mengevaluasi model

  model --> model yang telah dilatih, bisa lebih dari 1 atau 1 tetapi harus dalam list
  y_pred --> hasil prediksi model dari data uji
  name --> nama dari model yang ingin dievaluasi

  return DataFrame dari accuracy, precision, recall, f1-score, dan confusion matrix
  """

  data = {}

  for i in range(len(model)):
    accuracy = round(accuracy_score(y_test, y_pred[i]), 2)
    precision = round(precision_score(y_test, y_pred[i]), 2)
    recall = round(recall_score(y_test, y_pred[1]), 2)
    f1 = round(f1_score(y_test, y_pred[i]), 2)

    data[name[i]] = [accuracy, precision, recall, f1]

    cm = confusion_matrix(y_test, y_pred[i])

    plt.figure(figsize=(10,6))
    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', linewidths=0.2, xticklabels=['True', 'False'], yticklabels=['True', 'False'])
    plt.title(f'Confusion Matrix dari model {name[i]}')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.show()

  print(pd.DataFrame(data, index=['Accuracy', 'Precision', 'Recall', 'F1']))

# Menjalankan Fungsi evaluate
evaluate([knn, rf], [y_pred_knn, y_pred_rf], ['K-Nearest Neighbors', 'RandomForestClassifier'])

"""Metrik yang saya gunakan untuk model klasifikasi ini adalah Accuracy, Precision, Recall, dan F1-Score

* **Accuracy** adalah Persentase prediksi benar (True Positive + True Negative) dibandingkan dengan seluruh prediksi.

* **Precision** adalah Dari semua prediksi positif, berapa banyak yang benar-benar positif.

* **Recall** adalah Dari semua kasus positif aktual, berapa banyak yang berhasil diprediksi.

* **F1-Score** adalah Rata-rata harmonik dari precision dan recall. Berguna ketika perlu menyeimbangkan keduanya.


Dari akurasi tersebut dapat saya simpulkan kalau model RandomForestClassifer adalah model yang tepat untuk mesalah berikut dikarenakan metriks yang dihasilkan hampir sempurna, sedangkan untuk

## Export Model
"""

import joblib

joblib.dump(rf, 'rf_model.pkl')
joblib.dump(encoder, 'encoder.pkl')
joblib.dump(scaler, 'scaler.pkl')